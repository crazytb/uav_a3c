"""
ìì› ì‚¬ìš© íŒ¨í„´ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- ê° workerì˜ ë¡œì»¬ ìì›ì´ ì‹¤ì œë¡œ ë¶€ì¡±í•´ì§€ëŠ”ì§€ í™•ì¸
- OFFLOADê°€ í•„ìš”í•œ ìƒí™©ì´ ë°œìƒí•˜ëŠ”ì§€ ê²€ì¦
"""

import numpy as np
from drl_framework.custom_env import CustomEnv
from drl_framework.params import ENV_PARAMS, REWARD_PARAMS

def analyze_resource_patterns(num_episodes=100, max_steps=100):
    """í™˜ê²½ì—ì„œ ìì› ì‚¬ìš© íŒ¨í„´ ë¶„ì„"""

    env = CustomEnv(
        max_comp_units=ENV_PARAMS['max_comp_units'],
        max_epoch_size=ENV_PARAMS['max_epoch_size'],
        max_queue_size=ENV_PARAMS['max_queue_size'],
        max_comp_units_for_cloud=ENV_PARAMS['max_comp_units_for_cloud'],
        reward_weights=ENV_PARAMS['reward_weights'],
        agent_velocities=ENV_PARAMS['agent_velocities'],
        reward_params=REWARD_PARAMS
    )

    # í†µê³„ ìˆ˜ì§‘
    stats = {
        'local_possible': [],
        'offload_possible': [],
        'both_possible': [],
        'neither_possible': [],
        'available_resources': [],
        'queue_sizes': [],
        'channel_good': [],
        'mec_queue_full': [],
        'cloud_queue_full': []
    }

    for episode in range(num_episodes):
        obs, _ = env.reset()

        for step in range(max_steps):
            # í˜„ì¬ ìƒíƒœ ê¸°ë¡
            stats['available_resources'].append(env.available_computation_units)
            stats['queue_sizes'].append(env.queue_comp_units)
            stats['channel_good'].append(1 if env.channel_quality == 1 else 0)

            # MEC/Cloud í ìƒíƒœ
            mec_full = (env.mec_comp_units[env.mec_comp_units == 0].size == 0)
            cloud_full = (env.cloud_comp_units[env.cloud_comp_units == 0].size == 0)
            stats['mec_queue_full'].append(1 if mec_full else 0)
            stats['cloud_queue_full'].append(1 if cloud_full else 0)

            # ê° ì•¡ì…˜ì˜ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            local_possible = (
                (env.available_computation_units >= env.queue_comp_units) and
                (env.mec_comp_units[env.mec_comp_units == 0].size > 0) and
                (env.queue_comp_units > 0)
            )

            offload_possible = (
                (env.available_computation_units_for_cloud >= env.queue_comp_units) and
                (env.cloud_comp_units[env.cloud_comp_units == 0].size > 0) and
                (env.queue_comp_units > 0) and
                (env.channel_quality == 1)
            )

            stats['local_possible'].append(1 if local_possible else 0)
            stats['offload_possible'].append(1 if offload_possible else 0)
            stats['both_possible'].append(1 if (local_possible and offload_possible) else 0)
            stats['neither_possible'].append(1 if (not local_possible and not offload_possible) else 0)

            # ëœë¤ ì•¡ì…˜ìœ¼ë¡œ í™˜ê²½ ì§„í–‰
            valid_actions = env.get_valid_actions()
            action = np.random.choice(valid_actions)
            obs, reward, done, truncated, info = env.step(action)

            if done:
                break

    # ê²°ê³¼ ì¶œë ¥
    print("=" * 70)
    print("ğŸ” ìì› ì‚¬ìš© íŒ¨í„´ ë¶„ì„ ê²°ê³¼")
    print("=" * 70)
    print(f"\nğŸ“Š ì´ ë¶„ì„ ìŠ¤í… ìˆ˜: {len(stats['local_possible'])}")

    print("\n" + "=" * 70)
    print("ğŸ’¾ ìì› ê°€ìš©ì„± ë¶„ì„")
    print("=" * 70)
    print(f"í‰ê·  ê°€ìš© ìì›: {np.mean(stats['available_resources']):.2f} / {ENV_PARAMS['max_comp_units']}")
    print(f"ìµœì†Œ ê°€ìš© ìì›: {np.min(stats['available_resources'])}")
    print(f"ìµœëŒ€ ê°€ìš© ìì›: {np.max(stats['available_resources'])}")
    print(f"ê°€ìš© ìì› í‘œì¤€í¸ì°¨: {np.std(stats['available_resources']):.2f}")

    print("\n" + "=" * 70)
    print("ğŸ“¦ ì‘ì—… í¬ê¸° ë¶„ì„")
    print("=" * 70)
    print(f"í‰ê·  í í¬ê¸° (comp_units): {np.mean(stats['queue_sizes']):.2f}")
    print(f"ìµœì†Œ í í¬ê¸°: {np.min(stats['queue_sizes'])}")
    print(f"ìµœëŒ€ í í¬ê¸°: {np.max(stats['queue_sizes'])}")
    print(f"í í¬ê¸° í‘œì¤€í¸ì°¨: {np.std(stats['queue_sizes']):.2f}")

    # ìì› ë¶€ì¡± ë¹„ìœ¨
    resource_shortage = sum(1 for i in range(len(stats['available_resources']))
                           if stats['available_resources'][i] < stats['queue_sizes'][i])
    print(f"\nâš ï¸  ìì› ë¶€ì¡± ë°œìƒ ë¹„ìœ¨: {resource_shortage / len(stats['available_resources']) * 100:.1f}%")
    print(f"   (ê°€ìš© ìì› < í í¬ê¸°ì¸ ê²½ìš°)")

    print("\n" + "=" * 70)
    print("ğŸ¬ ì•¡ì…˜ ê°€ëŠ¥ì„± ë¶„ì„")
    print("=" * 70)
    local_pct = np.mean(stats['local_possible']) * 100
    offload_pct = np.mean(stats['offload_possible']) * 100
    both_pct = np.mean(stats['both_possible']) * 100
    neither_pct = np.mean(stats['neither_possible']) * 100

    print(f"LOCAL ê°€ëŠ¥:          {local_pct:5.1f}%")
    print(f"OFFLOAD ê°€ëŠ¥:        {offload_pct:5.1f}%")
    print(f"ë‘˜ ë‹¤ ê°€ëŠ¥:          {both_pct:5.1f}%")
    print(f"ë‘˜ ë‹¤ ë¶ˆê°€ëŠ¥:        {neither_pct:5.1f}%")
    print(f"DISCARDë§Œ ê°€ëŠ¥:      {neither_pct:5.1f}%")

    print("\n" + "=" * 70)
    print("ğŸ“¡ ì±„ë„ í’ˆì§ˆ ë¶„ì„")
    print("=" * 70)
    channel_good_pct = np.mean(stats['channel_good']) * 100
    print(f"ì±„ë„ ì¢‹ìŒ (quality=1): {channel_good_pct:.1f}%")
    print(f"ì±„ë„ ë‚˜ì¨ (quality=0): {100-channel_good_pct:.1f}%")

    print("\n" + "=" * 70)
    print("ğŸ—„ï¸  í í¬í™” ìƒíƒœ ë¶„ì„")
    print("=" * 70)
    mec_full_pct = np.mean(stats['mec_queue_full']) * 100
    cloud_full_pct = np.mean(stats['cloud_queue_full']) * 100
    print(f"MEC í ê°€ë“ ì°¸:      {mec_full_pct:.1f}%")
    print(f"Cloud í ê°€ë“ ì°¸:    {cloud_full_pct:.1f}%")

    print("\n" + "=" * 70)
    print("ğŸ¯ OFFLOAD í•„ìš”ì„± ë¶„ì„")
    print("=" * 70)

    # OFFLOADê°€ ì‹¤ì œë¡œ í•„ìš”í•œ ê²½ìš° = LOCAL ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ OFFLOAD ê°€ëŠ¥
    offload_needed = sum(1 for i in range(len(stats['local_possible']))
                        if not stats['local_possible'][i] and stats['offload_possible'][i])
    offload_needed_pct = offload_needed / len(stats['local_possible']) * 100

    print(f"OFFLOAD í•„ìˆ˜ ìƒí™©:   {offload_needed_pct:.1f}%")
    print(f"   (LOCAL ë¶ˆê°€ëŠ¥ & OFFLOAD ê°€ëŠ¥)")

    # LOCALë§Œ ê°€ëŠ¥í•œ ê²½ìš°
    local_only = sum(1 for i in range(len(stats['local_possible']))
                    if stats['local_possible'][i] and not stats['offload_possible'][i])
    local_only_pct = local_only / len(stats['local_possible']) * 100
    print(f"LOCALë§Œ ê°€ëŠ¥:        {local_only_pct:.1f}%")

    # OFFLOADë§Œ ê°€ëŠ¥í•œ ê²½ìš°
    offload_only = sum(1 for i in range(len(stats['local_possible']))
                      if not stats['local_possible'][i] and stats['offload_possible'][i])
    offload_only_pct = offload_only / len(stats['local_possible']) * 100
    print(f"OFFLOADë§Œ ê°€ëŠ¥:      {offload_only_pct:.1f}%")

    print("\n" + "=" * 70)
    print("ğŸ’¡ ê²°ë¡ ")
    print("=" * 70)

    if offload_needed_pct < 5:
        print("âš ï¸  OFFLOADê°€ í•„ìš”í•œ ìƒí™©ì´ ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("   â†’ í™˜ê²½ ì„¤ê³„ê°€ OFFLOAD í•™ìŠµì„ ìœ ë„í•˜ì§€ ëª»í•¨")
    elif offload_needed_pct < 20:
        print("âš ï¸  OFFLOADê°€ í•„ìš”í•œ ìƒí™©ì´ ë“œë­…ë‹ˆë‹¤.")
        print("   â†’ OFFLOAD í•™ìŠµì— ì¶©ë¶„í•œ ìƒ˜í”Œ ë¶€ì¡± ê°€ëŠ¥ì„±")
    else:
        print("âœ… OFFLOADê°€ í•„ìš”í•œ ìƒí™©ì´ ì¶©ë¶„íˆ ë°œìƒí•©ë‹ˆë‹¤.")

    if both_pct > 50:
        print("âœ… ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì„ íƒì§€ê°€ ìˆì–´ í•™ìŠµ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    if neither_pct > 30:
        print("âš ï¸  ì„ íƒì§€ê°€ ì—†ëŠ” ìƒí™©ì´ ë§ìŠµë‹ˆë‹¤ (DISCARD ê°•ì œ).")

    print("\n" + "=" * 70)

if __name__ == "__main__":
    analyze_resource_patterns(num_episodes=100, max_steps=100)
